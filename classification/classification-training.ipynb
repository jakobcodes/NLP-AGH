{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classifier training (1-6)\n",
    "### Jakub ≈Åubkowski, Marcin Miku≈Ça\n",
    "\n",
    "1. Use the FIQA-PL dataset that was used in lab 1 **and** lab lab 2 (so we need the passages, the questions and their\n",
    "   relations).\n",
    "2. Create a dataset of positive and negative sentence pairs.\n",
    "   - In each pair the first element is a question and the second element is a passagei, i.e. \"{question} {separator} {passage}\",\n",
    "      where `separator` should be a separator taken from the model's tokenizer.\n",
    "   - Use the relations to mark the positive pairs (i.e. pairs where the question is answered\n",
    "      by the passage).\n",
    "   - Use your own strategy to mark negative pairs (i.e. you can draw the negative examples, but there are\n",
    "      better strategies to define the negative examples). The number of negative examples should be larger than the\n",
    "      number of positive examples.\n",
    "3. The dataset from point 2 should be split into training, evaluation and testing subsets.\n",
    "4. Train a text classifier using the Transformers library that distinguishes between the positive and the negative\n",
    "   pairs. To make the process manageable use models of size `base` and a runtime providing GPU/TPU acceleration.\n",
    "   Consult the discussions related to fine-tuning Transformer models to select sensible set of parameters.\n",
    "   You can also run several trainings with different hyper-parameters, if you have access to large computing resources.\n",
    "5. Make sure you monitor the relevant metrics on the validation set during training. The last saved model might not be the\n",
    "   one with the best performance.\n",
    "6. Report the results you have obtained for the model. Use appropriate measures, since the dataset is not balanced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['_id', 'title', 'text'], dtype='object')\n",
      "Index(['_id', 'title', 'text_query'], dtype='object')\n",
      "Index(['query-id', 'corpus-id', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "ds = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")\n",
    "corpus_df = pd.DataFrame(ds['corpus'])\n",
    "\n",
    "q_data = load_dataset(\"clarin-knext/fiqa-pl\", \"queries\")\n",
    "q_df = pd.DataFrame(q_data['queries'])\n",
    "\n",
    "qa_data = load_dataset(\"clarin-knext/fiqa-pl-qrels\")['test']\n",
    "qa_df = pd.DataFrame(qa_data)\n",
    "\n",
    "q_df = q_df.rename(columns={'text': 'text_query'})\n",
    "\n",
    "print(corpus_df.columns)\n",
    "print(q_df.columns)\n",
    "print(qa_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df['query-id'] = qa_df['query-id'].astype(str)\n",
    "q_df['_id'] = q_df['_id'].astype(str)\n",
    "qa_df['corpus-id'] = qa_df['corpus-id'].astype(str)\n",
    "corpus_df['_id'] = corpus_df['_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs = pd.merge(\n",
    "    qa_df, \n",
    "    q_df[['_id', 'text_query']], \n",
    "    left_on='query-id', \n",
    "    right_on='_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs = pd.merge(\n",
    "    positive_pairs,\n",
    "    corpus_df[['_id', 'text']],\n",
    "    left_on='corpus-id',\n",
    "    right_on='_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For negative pairs, let's use a smart strategy:\n",
    "# 1. For each question, use passages that were matched with other questions\n",
    "# 2. This ensures the negative examples are challenging, as they were relevant for some questions\n",
    "def create_negative_pairs(positive_pairs, corpus_df, n_negative_per_positive=2):\n",
    "    negative_pairs = []\n",
    "    \n",
    "    for _, row in positive_pairs.iterrows():\n",
    "        # Get passages that weren't paired with this question\n",
    "        negative_passages = corpus_df[\n",
    "            ~corpus_df['_id'].isin(\n",
    "                positive_pairs[positive_pairs['query-id'] == row['query-id']]['corpus-id']\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Sample n random negative passages\n",
    "        negative_samples = negative_passages.sample(\n",
    "            n=min(n_negative_per_positive, len(negative_passages))\n",
    "        )\n",
    "        \n",
    "        for _, neg_row in negative_samples.iterrows():\n",
    "            negative_pairs.append({\n",
    "                'query-id': row['query-id'],\n",
    "                'corpus-id': neg_row['_id'],\n",
    "                'text_query': row['text_query'],\n",
    "                'text': neg_row['text'],\n",
    "                'is_positive': 0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(negative_pairs)\n",
    "\n",
    "negative_pairs_df = create_negative_pairs(positive_pairs, corpus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add positive label to positive pairs\n",
    "positive_pairs['is_positive'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only needed columns and combine positive and negative pairs\n",
    "final_pairs = pd.concat([\n",
    "    positive_pairs[['query-id', 'corpus-id', 'text_query', 'text', 'is_positive']],\n",
    "    negative_pairs_df\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add the formatted text pairs\n",
    "# We'll use [SEP] as a placeholder - we'll replace it with the actual model separator later\n",
    "final_pairs['text_pair'] = final_pairs['text_query'] + ' [SEP] ' + final_pairs['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 5118\n",
      "Positive pairs: 1706\n",
      "Negative pairs: 3412\n"
     ]
    }
   ],
   "source": [
    "# Show some statistics\n",
    "print(f\"Total pairs: {len(final_pairs)}\")\n",
    "print(f\"Positive pairs: {len(final_pairs[final_pairs['is_positive'] == 1])}\")\n",
    "print(f\"Negative pairs: {len(final_pairs[final_pairs['is_positive'] == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>text_query</th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive</th>\n",
       "      <th>text_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>566392</td>\n",
       "      <td>Jak zdeponowaƒá czek wystawiony na wsp√≥≈Çpracown...</td>\n",
       "      <td>Popro≈õ o ponowne wystawienie czeku w≈Ça≈õciwemu ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jak zdeponowaƒá czek wystawiony na wsp√≥≈Çpracown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>65404</td>\n",
       "      <td>Jak zdeponowaƒá czek wystawiony na wsp√≥≈Çpracown...</td>\n",
       "      <td>Po prostu popro≈õ wsp√≥≈Çpracownika o podpisanie ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jak zdeponowaƒá czek wystawiony na wsp√≥≈Çpracown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>325273</td>\n",
       "      <td>Czy mogƒô wys≈Çaƒá przekaz pieniƒô≈ºny z USPS jako ...</td>\n",
       "      <td>Oczywi≈õcie ≈ºe mo≈ºesz. W sekcji Od przekazu pie...</td>\n",
       "      <td>1</td>\n",
       "      <td>Czy mogƒô wys≈Çaƒá przekaz pieniƒô≈ºny z USPS jako ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>88124</td>\n",
       "      <td>1 EIN prowadzƒÖcy dzia≈Çalno≈õƒá pod wieloma nazwa...</td>\n",
       "      <td>Mylisz tutaj wiele rzeczy. Sp√≥≈Çka B LLC bƒôdzie...</td>\n",
       "      <td>1</td>\n",
       "      <td>1 EIN prowadzƒÖcy dzia≈Çalno≈õƒá pod wieloma nazwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>285255</td>\n",
       "      <td>Ubieganie siƒô o kredyt biznesowy i otrzymywani...</td>\n",
       "      <td>‚ÄûObawiam siƒô, ≈ºe wielkim mitem sp√≥≈Çek z ograni...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ubieganie siƒô o kredyt biznesowy i otrzymywani...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query-id corpus-id                                         text_query  \\\n",
       "0        8    566392  Jak zdeponowaƒá czek wystawiony na wsp√≥≈Çpracown...   \n",
       "1        8     65404  Jak zdeponowaƒá czek wystawiony na wsp√≥≈Çpracown...   \n",
       "2       15    325273  Czy mogƒô wys≈Çaƒá przekaz pieniƒô≈ºny z USPS jako ...   \n",
       "3       18     88124  1 EIN prowadzƒÖcy dzia≈Çalno≈õƒá pod wieloma nazwa...   \n",
       "4       26    285255  Ubieganie siƒô o kredyt biznesowy i otrzymywani...   \n",
       "\n",
       "                                                text  is_positive  \\\n",
       "0  Popro≈õ o ponowne wystawienie czeku w≈Ça≈õciwemu ...            1   \n",
       "1  Po prostu popro≈õ wsp√≥≈Çpracownika o podpisanie ...            1   \n",
       "2  Oczywi≈õcie ≈ºe mo≈ºesz. W sekcji Od przekazu pie...            1   \n",
       "3  Mylisz tutaj wiele rzeczy. Sp√≥≈Çka B LLC bƒôdzie...            1   \n",
       "4  ‚ÄûObawiam siƒô, ≈ºe wielkim mitem sp√≥≈Çek z ograni...            1   \n",
       "\n",
       "                                           text_pair  \n",
       "0  Jak zdeponowaƒá czek wystawiony na wsp√≥≈Çpracown...  \n",
       "1  Jak zdeponowaƒá czek wystawiony na wsp√≥≈Çpracown...  \n",
       "2  Czy mogƒô wys≈Çaƒá przekaz pieniƒô≈ºny z USPS jako ...  \n",
       "3  1 EIN prowadzƒÖcy dzia≈Çalno≈õƒá pod wieloma nazwa...  \n",
       "4  Ubieganie siƒô o kredyt biznesowy i otrzymywani...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: 80% train+val, 20% test\n",
    "train_val_df, test_df = train_test_split(\n",
    "    final_pairs,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=final_pairs['is_positive']  # Maintain the same positive/negative ratio\n",
    ")\n",
    "\n",
    "# Second split: Split remaining 80% into 80% train, 20% validation (64% and 16% of total)\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_val_df['is_positive']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training split statistics:\n",
      "Total samples: 3275\n",
      "Positive samples: 1092 (33.3%)\n",
      "Negative samples: 2183 (66.7%)\n",
      "\n",
      "Validation split statistics:\n",
      "Total samples: 819\n",
      "Positive samples: 273 (33.3%)\n",
      "Negative samples: 546 (66.7%)\n",
      "\n",
      "Test split statistics:\n",
      "Total samples: 1024\n",
      "Positive samples: 341 (33.3%)\n",
      "Negative samples: 683 (66.7%)\n"
     ]
    }
   ],
   "source": [
    "# Print statistics for each split\n",
    "def print_split_stats(split_df, name):\n",
    "    total = len(split_df)\n",
    "    positives = len(split_df[split_df['is_positive'] == 1])\n",
    "    negatives = len(split_df[split_df['is_positive'] == 0])\n",
    "    print(f\"\\n{name} split statistics:\")\n",
    "    print(f\"Total samples: {total}\")\n",
    "    print(f\"Positive samples: {positives} ({positives/total*100:.1f}%)\")\n",
    "    print(f\"Negative samples: {negatives} ({negatives/total*100:.1f}%)\")\n",
    "\n",
    "print_split_stats(train_df, \"Training\")\n",
    "print_split_stats(val_df, \"Validation\")\n",
    "print_split_stats(test_df, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a Polish BERT model\n",
    "model_name = \"dkleczek/bert-base-polish-uncased-v1\"\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df):\n",
    "    # Convert to huggingface dataset\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "    \n",
    "    # Tokenize function\n",
    "    def tokenize(batch):\n",
    "        # Replace placeholder [SEP] with the model's actual separator\n",
    "        texts = [\n",
    "            text.replace(\"[SEP]\", tokenizer.sep_token) \n",
    "            for text in batch['text_pair']\n",
    "        ]\n",
    "        \n",
    "        return tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "    \n",
    "    # Tokenize the dataset\n",
    "    dataset = dataset.map(\n",
    "        tokenize, \n",
    "        batched=True, \n",
    "        remove_columns=dataset.column_names\n",
    "    )\n",
    "    \n",
    "    # Add labels\n",
    "    dataset = dataset.add_column(\"labels\", df['is_positive'].values)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3275/3275 [00:00<00:00, 3917.59 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 819/819 [00:00<00:00, 3541.26 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1024/1024 [00:00<00:00, 4013.72 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = prepare_dataset(train_df)\n",
    "val_dataset = prepare_dataset(val_df)\n",
    "test_dataset = prepare_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics computation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, \n",
    "        preds, \n",
    "        average='binary'\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dkleczek/bert-base-polish-uncased-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakub_lubkowski/Documents/SEM9/pjn/.venv/lib/python3.9/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    # Enable fp16 if you have GPU\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñã        | 100/615 [02:00<09:28,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6158, 'grad_norm': 8.54408073425293, 'learning_rate': 1e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 200/615 [03:51<07:39,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4638, 'grad_norm': 7.661561012268066, 'learning_rate': 2e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 300/615 [11:02<20:31,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3419, 'grad_norm': 3.0003573894500732, 'learning_rate': 3e-05, 'epoch': 1.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 400/615 [17:53<14:59,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3447, 'grad_norm': 3.99796986579895, 'learning_rate': 4e-05, 'epoch': 1.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 500/615 [24:44<09:29,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.227, 'grad_norm': 5.7888312339782715, 'learning_rate': 5e-05, 'epoch': 2.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 500/615 [25:05<09:29,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4238881766796112, 'eval_accuracy': 0.8791208791208791, 'eval_f1': 0.8241563055062167, 'eval_precision': 0.8, 'eval_recall': 0.8498168498168498, 'eval_runtime': 20.0137, 'eval_samples_per_second': 40.922, 'eval_steps_per_second': 2.598, 'epoch': 2.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 600/615 [33:12<01:18,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2375, 'grad_norm': 3.6855883598327637, 'learning_rate': 6.521739130434783e-06, 'epoch': 2.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 615/615 [34:36<00:00,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2076.9372, 'train_samples_per_second': 4.731, 'train_steps_per_second': 0.296, 'train_loss': 0.36545832273436757, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=615, training_loss=0.36545832273436757, metrics={'train_runtime': 2076.9372, 'train_samples_per_second': 4.731, 'train_steps_per_second': 0.296, 'total_flos': 2585066118912000.0, 'train_loss': 0.36545832273436757, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 64/64 [00:23<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set results: {'eval_loss': 0.4298664927482605, 'eval_accuracy': 0.8701171875, 'eval_f1': 0.8113475177304964, 'eval_precision': 0.7857142857142857, 'eval_recall': 0.8387096774193549, 'eval_runtime': 24.6396, 'eval_samples_per_second': 41.559, 'eval_steps_per_second': 2.597, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(\"\\nTest set results:\", test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "   \"eval_loss\":0.4298664927482605,\n",
    "   \"eval_accuracy\":0.8701171875,\n",
    "   \"eval_f1\":0.8113475177304964,\n",
    "   \"eval_precision\":0.7857142857142857,\n",
    "   \"eval_recall\":0.8387096774193549,\n",
    "   \"eval_runtime\":24.6396,\n",
    "   \"eval_samples_per_second\":41.559,\n",
    "   \"eval_steps_per_second\":2.597,\n",
    "   \"epoch\":3.0\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer/tokenizer_config.json',\n",
       " 'tokenizer/special_tokens_map.json',\n",
       " 'tokenizer/vocab.txt',\n",
       " 'tokenizer/added_tokens.json',\n",
       " 'tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"model\")\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
